# Private vpn-server instance deploy
resource "aws_instance" "vpn-server" {
  # The connection block tells our provisioner how to
  # communicate with the resource (instance)
  connection {
    # The default username for our AMI
    user = "${module.aws-tested-oses.user}"

    # The connection will use the local SSH vpn-server for authentication.
  }

  root_block_device {
    volume_size = "${var.aws_agent_instance_disk_size}"
  }

  count = "1"
  instance_type = "t2.micro"
  ebs_optimized = "true"

  tags {
   owner = "${coalesce(var.owner, data.external.whoami.result["owner"])}"
   expiration = "${var.expiration}"
   Name =  "${data.template_file.cluster-name.rendered}-vpn-server-${count.index + 1}"
   cluster = "${data.template_file.cluster-name.rendered}"
  }
  ami = "ami-0f485b76"

  # The name of our SSH keypair we created above.
  key_name = "${var.key_name}"

  # Our Security group to allow http and SSH access
  vpc_security_group_ids = ["${aws_security_group.private_slave.id}","${aws_security_group.admin.id}","${aws_security_group.any_access_internal.id}"]

  # We're going to launch into the same subnet as our ELB. In a production
  # environment it's more common to have a separate private subnet for
  # backend instances.
  subnet_id = "${aws_subnet.private.id}"

  # OS init script
  #provisioner "file" {
  # content = "${module.aws-tested-oses.os-setup}"
  # destination = "/tmp/os-setup.sh"
  # }

 # We run a remote provisioner on the instance after creating it.
  # In this case, we just install nginx and start it. By default,
  # this should be on port 80
  #  provisioner "remote-exec" {
  #  inline = [
  #    "sudo chmod +x /tmp/os-setup.sh",
  #    "sudo bash /tmp/os-setup.sh",
  #  ]
  #}

  lifecycle {
    ignore_changes = ["tags.Name"]
  }
}

# Execute generated script on vpn-server
resource "null_resource" "vpn-server" {
  # Changes to any instance of the cluster requires re-provisioning
  triggers {
    current_ec2_instance_id = "${aws_instance.vpn-server.*.id[count.index]}"
  }
  # Bootstrap script can run on any instance of the cluster
  # So we just choose the first in this case
  connection {
    host = "${element(aws_instance.vpn-server.*.public_ip, count.index)}"
    user = "${module.aws-tested-oses.user}"
  }

  count = "1"

  # Generate and upload vpn-server script to node
  #provisioner "file" {
  #  content     = "${module.dcos-mesos-vpn-server.script}"
  #  destination = "run.sh"
  #}

  # Install Slave Node
  #provisioner "remote-exec" {
  #  inline = [
  #    "sudo chmod +x run.sh",
  #    "sudo ./run.sh",
  #  ]
  #}
}

output "Private vpn-server Public IP Address" {
  value = ["${aws_instance.vpn-server.*.public_ip}"]
}
